{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtamyreddy/NLP/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using RNN to predict the next word in the sentence/para ,once we give the input**"
      ],
      "metadata": {
        "id": "EsPhH-J5p6EE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q4xcW94R_aLJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN,Embedding,Dense\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c__vX2m__ras",
        "outputId": "374479fe-7c97-49d9-c0b0-df53e966d693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m r. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly normal, thank you very much. they were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n",
            "\n",
            "mr. dursley was the director of a firm called grunnings, which made drills. he was a big, beefy man with hardly any neck, although he did have a very large mustache. mrs. dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. the dursleys had a small son called dudley and in their opinion there was no finer boy anywhere.\n",
            "\n",
            "the dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. they didn’t think they could bear it if anyone found out about the potters. mrs. potter was mrs. dursley’s sister, but they hadn’t met for several years; in fact, mrs. dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as undursleyish as it was possible to be. the dursleys shuddered to think what the neighbors would say if the potters arrived in the street. the dursleys knew that the potters had a small son, too, but they had never even seen him. this boy was another good reason for keeping the potters away; they didn’t want dudley mixing with a child like that.\n",
            "\n",
            "when mr. and mrs. dursley wok\n"
          ]
        }
      ],
      "source": [
        "#Load the data and preprocessing the datta\n",
        "def load_data(file_path):\n",
        "  with open(file_path,'r', encoding='utf-8') as f:\n",
        "    text=f.read()\n",
        "  return text\n",
        "\n",
        "file_path = '/content/sample_data/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text=load_data(file_path).lower() #converting the text to lowercase\n",
        "print(text[:1500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcc29DU6AVgv",
        "outputId": "51774ce8-fed8-46ec-d092-cfd3ea5b0fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2162 3680    4  274  224    8  651  332  652  535   35 1268    5  164\n",
            "   20   21   35 1586  973 1587   14   69  157   21   35    2  141  128\n",
            "  653  789    5   32 1588   12  169  490  110 1416  142   21   68   55\n",
            "  909   25  505 1788  151  224   10    2 2701    8    6 2702  275 2703\n",
            "  140  183 1417    7   10    6  394 3681  333   25  491  191  593  974\n",
            "    7  131   36    6   69  233 1418  274  224   10  975    4 2704    4\n",
            "   17  343  689    2  594 3682    8  593  140  159   12   69 1789   22\n",
            "   46  910]\n",
            "53\n",
            "(80922, 100)\n",
            "(80922,)\n"
          ]
        }
      ],
      "source": [
        "#Tokenization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences #Padding\n",
        "\n",
        "# Out-Of-Vocabulary token\n",
        "# If a word not seen during training appears later, it will be replaced with <OOV>\n",
        "# Helps handle unknown words instead of ignoring them\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts([text]) #Mapping of words to unique integers\n",
        "total_words = len(tokenizer.word_index)+1 #Total number of unique words\n",
        "\n",
        "#convert text to Sequences\n",
        "input_sequences=[]\n",
        "tokens = tokenizer.texts_to_sequences([text])[0] #Converts input text into a list of number based on the word index\n",
        "seq_len = 100 #Each input contains 100 words\n",
        "\n",
        "# First seq_length tokens (input): Used for training the model.\n",
        "# Last token (target): Used as the label the model tries to predict.\n",
        "# so total of (50 + 1) in one input_sequence index\n",
        "\n",
        "for i in range(seq_len,len(tokens)):\n",
        "  input_sequences.append(tokens[i-seq_len:i+1])\n",
        "\n",
        "#Padding sequences and split inputs/targets\n",
        "#x will have inputs y will have outputs\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences,maxlen=seq_len +1, padding = 'pre'))\n",
        "x,y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "print(x[0])\n",
        "print(y[0])\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANU8-3RKIq9r",
        "outputId": "0b942890-816d-430d-fafc-286f67385063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#one hot encode the labels\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "#Build the simple RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=total_words, output_dim=50, input_length=seq_len),\n",
        "    SimpleRNN(300, return_sequences=True),\n",
        "    # 2300 in RNN - The number of hidden units (size of the hidden state vector)\n",
        "    SimpleRNN(300),\n",
        "    Dense(total_words, activation='softmax')\n",
        " ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kzze8JbJs_F",
        "outputId": "8a89ce32-c516-454d-e954-ea16d0f5fe77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 621ms/step - accuracy: 0.0404 - loss: 7.1334\n",
            "Epoch 2/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 622ms/step - accuracy: 0.0425 - loss: 6.8732\n",
            "Epoch 3/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 614ms/step - accuracy: 0.0412 - loss: 6.9760\n",
            "Epoch 4/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 623ms/step - accuracy: 0.0475 - loss: 6.6510\n",
            "Epoch 5/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 625ms/step - accuracy: 0.0624 - loss: 6.3398\n",
            "Epoch 6/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 616ms/step - accuracy: 0.0858 - loss: 6.0917\n",
            "Epoch 7/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 613ms/step - accuracy: 0.1000 - loss: 5.8589\n",
            "Epoch 8/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 614ms/step - accuracy: 0.1171 - loss: 5.5350\n",
            "Epoch 9/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 616ms/step - accuracy: 0.1281 - loss: 5.2496\n",
            "Epoch 10/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 614ms/step - accuracy: 0.1436 - loss: 4.9687\n",
            "Epoch 11/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 615ms/step - accuracy: 0.1545 - loss: 4.7061\n",
            "Epoch 12/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 618ms/step - accuracy: 0.1666 - loss: 4.4724\n",
            "Epoch 13/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 611ms/step - accuracy: 0.1849 - loss: 4.2626\n",
            "Epoch 14/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 616ms/step - accuracy: 0.2062 - loss: 4.0432\n",
            "Epoch 15/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 616ms/step - accuracy: 0.2261 - loss: 3.8574\n",
            "Epoch 16/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 615ms/step - accuracy: 0.2461 - loss: 3.6778\n",
            "Epoch 17/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 612ms/step - accuracy: 0.2736 - loss: 3.4907\n",
            "Epoch 18/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 612ms/step - accuracy: 0.2979 - loss: 3.3296\n",
            "Epoch 19/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 611ms/step - accuracy: 0.3169 - loss: 3.1898\n",
            "Epoch 20/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 613ms/step - accuracy: 0.3414 - loss: 3.0493\n",
            "Epoch 21/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 612ms/step - accuracy: 0.3622 - loss: 2.9198\n",
            "Epoch 22/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 607ms/step - accuracy: 0.3830 - loss: 2.7997\n",
            "Epoch 23/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 612ms/step - accuracy: 0.4072 - loss: 2.6724\n",
            "Epoch 24/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 608ms/step - accuracy: 0.4232 - loss: 2.5693\n",
            "Epoch 25/25\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 615ms/step - accuracy: 0.4438 - loss: 2.4448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0f102cbe90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#train the model\n",
        "model.fit(x, y, epochs=25,batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-fBNR_8lKRzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7df96ad-aefd-44fb-f249-c04d4bfbd346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harry at hogwarts his hands had broken a sound of people whooshing and the movements of magic already and what he had been forgotten to see the damage is — but it’s incredible he was fine of the first years in the world to get past fluffy but he didn’t have to be\n"
          ]
        }
      ],
      "source": [
        "# Function to generate text using RNN\n",
        "def generate_text(seed_text, next_words=50, seq_length=50): # Added seq_length with default value 100\n",
        "    for _ in range(next_words):\n",
        "        tokenized_input = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        tokenized_input = pad_sequences([tokenized_input], maxlen=seq_length, padding='pre') #seq_length is now in scope\n",
        "\n",
        "        predicted_probs = model.predict(tokenized_input, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, \"<OOV>\")\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "# Generate text using the trained model\n",
        "print(generate_text(\"harry at hogwarts\")) #all with the default seq_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qhtj3gxipwST"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaDaW0vrKVYvuPe9xmxGD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
