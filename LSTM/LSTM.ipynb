{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLx72zWZz+r0ElUZYcMNm1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtamyreddy/NLP/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4W7gzwSm_mzZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to load dataset\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r',encoding='utf-8') as f:\n",
        "      text = f.read()\n",
        "    return text\n",
        "\n",
        "#Load Harry Potter book text\n",
        "file_path ='/content/sample_data/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text = load_data(file_path).lower()\n",
        "\n",
        "#Tokenize the text\n",
        "tokenizer = Tokenizer(oov_token='<oov>')\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "#Convert text into Sequences\n",
        "input_sequences = []\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "seq_length = 100\n",
        "\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i-seq_length:i+1])\n",
        "\n",
        "#Padding sequences and split into iput and labels(x and y)\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length+1))\n",
        "x, y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)#one hot encoding\n",
        "\n"
      ],
      "metadata": {
        "id": "vsjnteQsAg0B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=seq_length),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    LSTM(256),\n",
        "    Dense(total_words,activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "model.fit(x, y, epochs=20, batch_size = 128)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtipTBF7BbAa",
        "outputId": "6a19d39d-378e-4b50-c7ec-f23f8abe47cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1260s\u001b[0m 2s/step - accuracy: 0.0444 - loss: 7.0586\n",
            "Epoch 2/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1271s\u001b[0m 2s/step - accuracy: 0.0526 - loss: 6.3805\n",
            "Epoch 3/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1277s\u001b[0m 2s/step - accuracy: 0.0784 - loss: 6.0739\n",
            "Epoch 4/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 2s/step - accuracy: 0.1023 - loss: 5.7593\n",
            "Epoch 5/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1276s\u001b[0m 2s/step - accuracy: 0.1130 - loss: 5.5373\n",
            "Epoch 6/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1275s\u001b[0m 2s/step - accuracy: 0.1179 - loss: 5.3834\n",
            "Epoch 7/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1229s\u001b[0m 2s/step - accuracy: 0.1295 - loss: 5.2791\n",
            "Epoch 8/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 2s/step - accuracy: 0.1424 - loss: 4.9896\n",
            "Epoch 9/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1273s\u001b[0m 2s/step - accuracy: 0.1583 - loss: 4.7374\n",
            "Epoch 10/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 2s/step - accuracy: 0.1700 - loss: 4.5232\n",
            "Epoch 11/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1228s\u001b[0m 2s/step - accuracy: 0.1821 - loss: 4.3134\n",
            "Epoch 12/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1277s\u001b[0m 2s/step - accuracy: 0.1967 - loss: 4.1064\n",
            "Epoch 13/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1321s\u001b[0m 2s/step - accuracy: 0.2218 - loss: 3.9118\n",
            "Epoch 14/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1237s\u001b[0m 2s/step - accuracy: 0.2435 - loss: 3.7264\n",
            "Epoch 15/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1230s\u001b[0m 2s/step - accuracy: 0.2672 - loss: 3.5509\n",
            "Epoch 16/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1213s\u001b[0m 2s/step - accuracy: 0.2930 - loss: 3.3714\n",
            "Epoch 17/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 2s/step - accuracy: 0.3186 - loss: 3.2147\n",
            "Epoch 18/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1208s\u001b[0m 2s/step - accuracy: 0.3411 - loss: 3.0692\n",
            "Epoch 19/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1225s\u001b[0m 2s/step - accuracy: 0.3683 - loss: 2.9185\n",
            "Epoch 20/20\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1217s\u001b[0m 2s/step - accuracy: 0.3906 - loss: 2.7838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ed492989590>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to generate Text\n",
        "def generate_text(seed_text, next_words=40,temperature = 1.0):\n",
        "  for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list],maxlen = seq_length,padding = 'pre')\n",
        "\n",
        "    predicted_probs = model.predict(token_list,verbose = 0)[0]\n",
        "    predicted_probs = np.asarray(predicted_probs)/temperature #Adjust parameters\n",
        "    predicted_probs = np.exp(predicted_probs)/np.sum(np.exp(predicted_probs))\n",
        "    predicted_index = np.random.choice(range(len(predicted_probs)),p=predicted_probs)\n",
        "\n",
        "    output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "    seed_text += \" \"+ output_word\n",
        "\n",
        "  return seed_text\n",
        "\n",
        "#Generate text\n",
        "print(generate_text(\"harry at hogwarts\",next_words = 50, temperature = 0.7))"
      ],
      "metadata": {
        "id": "9Ej_gvOBC-EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d14de8-6bae-4390-e462-a4447a3321e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harry at hogwarts narrowly fantastic touching…” weasleys cheers lunchtime possible below doom reflection er mist gasps favorite apart won’t poison report worked mahogany breathe “charlie master snowball ancient postcard dreadlocks long delivered lunged captain likes dormitories involved countercurses thumpin’ quaffle wander cobbled stutter “anyone “blown smiled supply parents…they seamus’s cloth archway peeves’s swearing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsJ3p2ATVaCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
